# -*- coding: utf-8 -*-
"""Autoencoder.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1S_WD1l-NR7xTbtZ96SkZ3-O9E9Zh6Toe
"""

import tensorflow as tf

from keras.datasets import mnist
from keras.models import Model
from keras.layers import Dense, Input

import matplotlib.pyplot as plt

(x_train,y_train),(x_test,y_test)=mnist.load_data()
x_train.shape

plt.imshow(x_train[0])

plt.imshow(x_test[0])

##Converting to vector

x_train = x_train.reshape(x_train.shape[0],28*28)
x_test = x_test.reshape(x_test.shape[0],28*28)
print(x_train.shape)
x_test.shape

##Rescaling
x_train.max()

x_train=x_train/255.0
x_test=x_test/255.0
x_train.max()

##Model

input_layer = Input(shape=x_train.shape[1])
bottleneck = Dense(32,activation='relu',name='bottleneck')(input_layer)
output = Dense(x_train.shape[1],activation='sigmoid',name='output')(bottleneck)

autoencoder= Model(input_layer,output)
autoencoder.summary()

encoder=Model(input_layer,bottleneck)
encoder.summary()

encoded_layer=Input(shape=(32,),name='encoded_layer')
decoder_layer=autoencoder.layers[-1]
decoder=Model(encoded_layer,decoder_layer(encoded_layer))
decoder.summary()

autoencoder.compile(loss='mse',optimizer='adam')
history=autoencoder.fit(x_train,x_train,epochs=20,batch_size=128)

plt.plot(history.history['loss'])

encoded_data = encoder.predict(x_test,batch_size=512)
encoded_data.shape

output_data=decoder.predict(encoded_data,batch_size=512)
output_data.shape

output_data=output_data.reshape(output_data.shape[0],28,28)
output_data.shape

plt.imshow(output_data[0],cmap='gray')

x_test = x_test.reshape(10000,28,28)
x_test.shape

plt.imshow(x_test[0],cmap='gray')

