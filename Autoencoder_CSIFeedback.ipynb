{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Z50_pIYI1vn1spx4fGm6TeamqkLhLUm0",
      "authorship_tag": "ABX9TyP06bpFp3SZHGEJTIGKoVLs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshaydc14/Autoencoder/blob/main/Autoencoder_CSIFeedback.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Input, Dense, BatchNormalization, Reshape, Conv2D, Add, LeakyReLU\n",
        "from keras.models import Model\n",
        "from keras.callbacks import TensorBoard, Callback\n",
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Reset the default graph (for compatibility)\n",
        "tf.compat.v1.reset_default_graph()\n",
        "\n",
        "envir = 'indoor'  # 'indoor' or 'outdoor'\n",
        "\n",
        "# Image params\n",
        "img_height = 32\n",
        "img_width = 32\n",
        "img_channels = 2\n",
        "img_total = img_height * img_width * img_channels\n",
        "\n",
        "# Network params\n",
        "residual_num = 2\n",
        "encoded_dim = 32  # compress rate=1/4->dim.=512, compress rate=1/16->dim.=128, compress rate=1/32->dim.=64, compress rate=1/64->dim.=32\n",
        "\n",
        "# Build the autoencoder model of CsiNet\n",
        "def residual_network(x, residual_num, encoded_dim):\n",
        "    def add_common_layers(y):\n",
        "        y = BatchNormalization()(y)\n",
        "        y = LeakyReLU()(y)\n",
        "        return y\n",
        "\n",
        "    def residual_block_decoded(y):\n",
        "        shortcut = y\n",
        "        y = Conv2D(8, kernel_size=(3, 3), padding='same', data_format='channels_last')(y)\n",
        "        y = add_common_layers(y)\n",
        "\n",
        "        y = Conv2D(16, kernel_size=(3, 3), padding='same', data_format='channels_last')(y)\n",
        "        y = add_common_layers(y)\n",
        "\n",
        "        y = Conv2D(2, kernel_size=(3, 3), padding='same', data_format='channels_last')(y)\n",
        "        y = BatchNormalization()(y)\n",
        "\n",
        "        y = Add()([shortcut, y])\n",
        "        y = LeakyReLU()(y)\n",
        "\n",
        "        return y\n",
        "\n",
        "    x = Conv2D(2, (3, 3), padding='same', data_format='channels_last')(x)\n",
        "    x = add_common_layers(x)\n",
        "\n",
        "    x = Reshape((img_total,))(x)\n",
        "    encoded = Dense(encoded_dim, activation='linear')(x)\n",
        "\n",
        "    x = Dense(img_total, activation='linear')(encoded)\n",
        "    x = Reshape((img_height, img_width, img_channels))(x)\n",
        "    for i in range(residual_num):\n",
        "        x = residual_block_decoded(x)\n",
        "\n",
        "    x = Conv2D(2, (3, 3), activation='sigmoid', padding='same', data_format='channels_last')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "image_tensor = Input(shape=(img_height, img_width, img_channels))\n",
        "network_output = residual_network(image_tensor, residual_num, encoded_dim)\n",
        "autoencoder = Model(inputs=[image_tensor], outputs=[network_output])\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "print(autoencoder.summary())\n",
        "\n",
        "# Data loading\n",
        "if envir == 'indoor':\n",
        "    mat = sio.loadmat('CSI/DATA_Htrainin.mat')\n",
        "    x_train = mat['HT']  # array\n",
        "    mat = sio.loadmat('CSI/DATA_Hvalin.mat')\n",
        "    x_val = mat['HT']  # array\n",
        "    mat = sio.loadmat('CSI/DATA_Htestin.mat')\n",
        "    x_test = mat['HT']  # array\n",
        "\n",
        "elif envir == 'outdoor':\n",
        "    mat = sio.loadmat('CSI/DATA_Htrainout.mat')\n",
        "    x_train = mat['HT']  # array\n",
        "    mat = sio.loadmat('CSI/DATA_Hvalout.mat')\n",
        "    x_val = mat['HT']  # array\n",
        "    mat = sio.loadmat('CSI/DATA_Htestout.mat')\n",
        "    x_test = mat['HT']  # array\n",
        "\n",
        "# Print the shape of the loaded data\n",
        "print(f\"x_train shape: {x_train.shape}\")\n",
        "print(f\"x_val shape: {x_val.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape}\")\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_val = x_val.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# Reshape data to (samples, height, width, channels)\n",
        "x_train = np.reshape(x_train, (len(x_train), img_height, img_width, img_channels))\n",
        "x_val = np.reshape(x_val, (len(x_val), img_height, img_width, img_channels))\n",
        "x_test = np.reshape(x_test, (len(x_test), img_height, img_width, img_channels))\n",
        "\n",
        "# Verify reshaped data\n",
        "print(f\"x_train reshaped shape: {x_train.shape}\")\n",
        "print(f\"x_val reshaped shape: {x_val.shape}\")\n",
        "print(f\"x_test reshaped shape: {x_test.shape}\")\n",
        "\n",
        "class LossHistory(Callback):\n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.losses_train = []\n",
        "        self.losses_val = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        self.losses_train.append(logs.get('loss'))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.losses_val.append(logs.get('val_loss'))\n",
        "\n",
        "history = LossHistory()\n",
        "file = 'CsiNet_' + envir + '_dim' + str(encoded_dim) + time.strftime('_%m_%d')\n",
        "path = 'result/TensorBoard_%s' % file\n",
        "\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=20,\n",
        "                batch_size=200,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_val, x_val),\n",
        "                callbacks=[history,\n",
        "                           TensorBoard(log_dir=path)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z3-r_AtitgR",
        "outputId": "24da4ea8-9676-4b4f-8321-af7f41963217"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 32, 32, 2)]          0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 32, 32, 2)            38        ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 32, 32, 2)            8         ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)     (None, 32, 32, 2)            0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " reshape (Reshape)           (None, 2048)                 0         ['leaky_re_lu[0][0]']         \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 32)                   65568     ['reshape[0][0]']             \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 2048)                 67584     ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)         (None, 32, 32, 2)            0         ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 8)            152       ['reshape_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 32, 32, 8)            32        ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 32, 32, 8)            0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 32, 32, 16)           1168      ['leaky_re_lu_1[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 32, 32, 16)           64        ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 32, 32, 16)           0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 2)            290       ['leaky_re_lu_2[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 32, 32, 2)            8         ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 32, 32, 2)            0         ['reshape_1[0][0]',           \n",
            "                                                                     'batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 32, 32, 2)            0         ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 8)            152       ['leaky_re_lu_3[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 32, 32, 8)            32        ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 32, 32, 8)            0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 32, 32, 16)           1168      ['leaky_re_lu_4[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 32, 32, 16)           64        ['conv2d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 32, 32, 16)           0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 2)            290       ['leaky_re_lu_5[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 32, 32, 2)            8         ['conv2d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 32, 32, 2)            0         ['leaky_re_lu_3[0][0]',       \n",
            "                                                                     'batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 32, 32, 2)            0         ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 32, 32, 2)            38        ['leaky_re_lu_6[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 136664 (533.84 KB)\n",
            "Trainable params: 136556 (533.42 KB)\n",
            "Non-trainable params: 108 (432.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "x_train shape: (100000, 2048)\n",
            "x_val shape: (30000, 2048)\n",
            "x_test shape: (20000, 2048)\n",
            "x_train reshaped shape: (100000, 32, 32, 2)\n",
            "x_val reshaped shape: (30000, 32, 32, 2)\n",
            "x_test reshaped shape: (20000, 32, 32, 2)\n",
            "Epoch 1/20\n",
            "500/500 [==============================] - 530s 1s/step - loss: 0.0011 - val_loss: 4.6269e-04\n",
            "Epoch 2/20\n",
            "500/500 [==============================] - 529s 1s/step - loss: 4.4848e-04 - val_loss: 4.4378e-04\n",
            "Epoch 3/20\n",
            "500/500 [==============================] - 531s 1s/step - loss: 4.3347e-04 - val_loss: 4.3185e-04\n",
            "Epoch 4/20\n",
            "500/500 [==============================] - 517s 1s/step - loss: 4.0113e-04 - val_loss: 4.2382e-04\n",
            "Epoch 5/20\n",
            "500/500 [==============================] - 515s 1s/step - loss: 3.6288e-04 - val_loss: 3.7774e-04\n",
            "Epoch 6/20\n",
            "500/500 [==============================] - 513s 1s/step - loss: 3.3137e-04 - val_loss: 3.6791e-04\n",
            "Epoch 7/20\n",
            "500/500 [==============================] - 513s 1s/step - loss: 3.0946e-04 - val_loss: 3.5523e-04\n",
            "Epoch 8/20\n",
            "500/500 [==============================] - 508s 1s/step - loss: 2.9367e-04 - val_loss: 2.9109e-04\n",
            "Epoch 9/20\n",
            "500/500 [==============================] - 508s 1s/step - loss: 2.8150e-04 - val_loss: 2.8033e-04\n",
            "Epoch 10/20\n",
            "500/500 [==============================] - 506s 1s/step - loss: 2.7236e-04 - val_loss: 2.7245e-04\n",
            "Epoch 11/20\n",
            "500/500 [==============================] - 511s 1s/step - loss: 2.6543e-04 - val_loss: 2.7067e-04\n",
            "Epoch 12/20\n",
            "500/500 [==============================] - 513s 1s/step - loss: 2.6041e-04 - val_loss: 2.7496e-04\n",
            "Epoch 13/20\n",
            "500/500 [==============================] - 511s 1s/step - loss: 2.5639e-04 - val_loss: 2.6887e-04\n",
            "Epoch 14/20\n",
            "500/500 [==============================] - 514s 1s/step - loss: 2.5298e-04 - val_loss: 2.8619e-04\n",
            "Epoch 15/20\n",
            "500/500 [==============================] - 514s 1s/step - loss: 2.5001e-04 - val_loss: 2.5888e-04\n",
            "Epoch 16/20\n",
            "500/500 [==============================] - 509s 1s/step - loss: 2.4732e-04 - val_loss: 2.6197e-04\n",
            "Epoch 17/20\n",
            "500/500 [==============================] - 503s 1s/step - loss: 2.4523e-04 - val_loss: 2.9979e-04\n",
            "Epoch 18/20\n",
            "500/500 [==============================] - 500s 1s/step - loss: 2.4339e-04 - val_loss: 2.6227e-04\n",
            "Epoch 19/20\n",
            "500/500 [==============================] - 506s 1s/step - loss: 2.4179e-04 - val_loss: 2.5004e-04\n",
            "Epoch 20/20\n",
            "500/500 [==============================] - 510s 1s/step - loss: 2.4040e-04 - val_loss: 2.5190e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x789416cd4370>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Input, Dense, BatchNormalization, Reshape, Conv2D, Add, LeakyReLU\n",
        "from keras.models import Model\n",
        "from keras.callbacks import TensorBoard, Callback, ReduceLROnPlateau\n",
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "# Calculate NMSE and rho\n",
        "def calculate_nmse_rho(x_test, x_hat):\n",
        "    x_test_real = np.reshape(x_test[:, :, :, 0], (len(x_test), -1))\n",
        "    x_test_imag = np.reshape(x_test[:, :, :, 1], (len(x_test), -1))\n",
        "    x_test_C = x_test_real - 0.5 + 1j * (x_test_imag - 0.5)\n",
        "\n",
        "    x_hat_real = np.reshape(x_hat[:, :, :, 0], (len(x_hat), -1))\n",
        "    x_hat_imag = np.reshape(x_hat[:, :, :, 1], (len(x_hat), -1))\n",
        "    x_hat_C = x_hat_real - 0.5 + 1j * (x_hat_imag - 0.5)\n",
        "\n",
        "    power = np.sum(np.abs(x_test_C) ** 2, axis=1)\n",
        "    mse = np.sum(np.abs(x_test_C - x_hat_C) ** 2, axis=1)\n",
        "    nmse = np.mean(mse / power)\n",
        "    nmse_db = 10 * np.log10(nmse)\n",
        "\n",
        "    rho = np.abs(np.sum(x_test_C * np.conj(x_hat_C), axis=1)) / (\n",
        "        np.sqrt(np.sum(np.abs(x_test_C) ** 2, axis=1)) * np.sqrt(np.sum(np.abs(x_hat_C) ** 2, axis=1)))\n",
        "    rho_mean = np.mean(rho)\n",
        "\n",
        "    return nmse_db, rho_mean\n",
        "\n",
        "# Evaluate the model\n",
        "tStart = time.time()\n",
        "x_hat = autoencoder.predict(x_test)\n",
        "tEnd = time.time()\n",
        "print(\"It cost %f sec\" % ((tEnd - tStart) / x_test.shape[0]))\n",
        "\n",
        "nmse, rho = calculate_nmse_rho(x_test, x_hat)\n",
        "print(f\"In {envir} environment\")\n",
        "print(f\"When dimension is {encoded_dim}\")\n",
        "print(f\"NMSE is {nmse}\")\n",
        "print(f\"Correlation is {rho}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLENkIcyi5ih",
        "outputId": "24010760-8e56-4e35-bbf7-3c4738ea7121"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 31s 49ms/step\n",
            "It cost 0.001634 sec\n",
            "In indoor environment\n",
            "When dimension is 32\n",
            "NMSE is -2.805953323841095\n",
            "Correlation is 0.7202038764953613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TtF5Bu7ej5wt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fFeDTo_Gj8Ol"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}